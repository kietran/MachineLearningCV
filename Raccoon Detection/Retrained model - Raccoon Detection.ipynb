{"cells":[{"cell_type":"markdown","metadata":{"id":"gCMycQ_2U8SA"},"source":["<div align=\"center\">\n","  <img src=\"https://github.com/open-mmlab/mmdetection/raw/3.x/resources/mmdet-logo.png\" width=\"600\"/>\n","  <div>&nbsp;</div>\n","  <div align=\"center\">\n","    <b><font size=\"5\">OpenMMLab website</font></b>\n","    <sup>\n","      <a href=\"https://openmmlab.com\">\n","        <i><font size=\"4\">HOT</font></i>\n","      </a>\n","    </sup>\n","    &nbsp;&nbsp;&nbsp;&nbsp;\n","    <b><font size=\"5\">OpenMMLab platform</font></b>\n","    <sup>\n","      <a href=\"https://platform.openmmlab.com\">\n","        <i><font size=\"4\">TRY IT OUT</font></i>\n","      </a>\n","    </sup>\n","  </div>\n","  <div>&nbsp;</div>\n","\n","<a href=\"https://colab.research.google.com/github/open-mmlab/mmdetection/blob/dev-3.x/demo/MMDet_Tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n","\n","[![PyPI](https://img.shields.io/pypi/v/mmdet)](https://pypi.org/project/mmdet)\n","[![docs](https://img.shields.io/badge/docs-latest-blue)](https://mmdetection.readthedocs.io/en/latest/)\n","[![badge](https://github.com/open-mmlab/mmdetection/workflows/build/badge.svg)](https://github.com/open-mmlab/mmdetection/actions)\n","[![codecov](https://codecov.io/gh/open-mmlab/mmdetection/branch/master/graph/badge.svg)](https://codecov.io/gh/open-mmlab/mmdetection)\n","[![license](https://img.shields.io/github/license/open-mmlab/mmdetection.svg)](https://github.com/open-mmlab/mmdetection/blob/master/LICENSE)\n","[![open issues](https://isitmaintained.com/badge/open/open-mmlab/mmdetection.svg)](https://github.com/open-mmlab/mmdetection/issues)\n","[![issue resolution](https://isitmaintained.com/badge/resolution/open-mmlab/mmdetection.svg)](https://github.com/open-mmlab/mmdetection/issues)\n","\n","[üìòDocumentation](https://mmdetection.readthedocs.io/en/3.x/) |\n","[üõ†Ô∏èInstallation](https://mmdetection.readthedocs.io/en/3.x/get_started.html) |\n","[üëÄModel Zoo](https://mmdetection.readthedocs.io/en/3.x/model_zoo.html) |\n","[üÜïUpdate News](https://mmdetection.readthedocs.io/en/3.x/notes/changelog.html) |\n","[üöÄOngoing Projects](https://github.com/open-mmlab/mmdetection/projects) |\n","[ü§îReporting Issues](https://github.com/open-mmlab/mmdetection/issues/new/choose)\n","\n","</div>\n","\n","<div align=\"center\">\n","  <a href=\"https://openmmlab.medium.com/\" style=\"text-decoration:none;\">\n","    <img src=\"https://user-images.githubusercontent.com/25839884/219255827-67c1a27f-f8c5-46a9-811d-5e57448c61d1.png\" width=\"3%\" alt=\"\" /></a>\n","  <img src=\"https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png\" width=\"3%\" alt=\"\" />\n","  <a href=\"https://discord.com/channels/1037617289144569886/1046608014234370059\" style=\"text-decoration:none;\">\n","    <img src=\"https://user-images.githubusercontent.com/25839884/218347213-c080267f-cbb6-443e-8532-8e1ed9a58ea9.png\" width=\"3%\" alt=\"\" /></a>\n","  <img src=\"https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png\" width=\"3%\" alt=\"\" />\n","  <a href=\"https://twitter.com/OpenMMLab\" style=\"text-decoration:none;\">\n","    <img src=\"https://user-images.githubusercontent.com/25839884/218346637-d30c8a0f-3eba-4699-8131-512fb06d46db.png\" width=\"3%\" alt=\"\" /></a>\n","  <img src=\"https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png\" width=\"3%\" alt=\"\" />\n","  <a href=\"https://www.youtube.com/openmmlab\" style=\"text-decoration:none;\">\n","    <img src=\"https://user-images.githubusercontent.com/25839884/218346691-ceb2116a-465a-40af-8424-9f30d2348ca9.png\" width=\"3%\" alt=\"\" /></a>\n","  <img src=\"https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png\" width=\"3%\" alt=\"\" />\n","  <a href=\"https://space.bilibili.com/1293512903\" style=\"text-decoration:none;\">\n","    <img src=\"https://user-images.githubusercontent.com/25839884/219026751-d7d14cce-a7c9-4e82-9942-8375fca65b99.png\" width=\"3%\" alt=\"\" /></a>\n","  <img src=\"https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png\" width=\"3%\" alt=\"\" />\n","  <a href=\"https://www.zhihu.com/people/openmmlab\" style=\"text-decoration:none;\">\n","    <img src=\"https://user-images.githubusercontent.com/25839884/219026120-ba71e48b-6e94-4bd4-b4e9-b7d175b5e362.png\" width=\"3%\" alt=\"\" /></a>\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"aGYwt_UjIrqp"},"source":["# Object Detection\n","\n","In this tutorial, you will learn:\n","- the basic structure of RTMDet.\n","- to perform inference with a MMDetection detector.\n","- to train a new detector with a new dataset.\n","\n","Let's start!\n","\n","```{note}\n","The commands in this tutorial are mainly for Colab.\n","You can click the button above, `Open in Colab`, to run this notebook in Colab.\n","```"]},{"cell_type":"markdown","metadata":{"id":"tJxJHruNLb7Y"},"source":["## Install MMDetection"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wi4LPmsR66sy","outputId":"96328b24-430b-4d5b-955d-807405d43662","executionInfo":{"status":"ok","timestamp":1691419899481,"user_tz":-420,"elapsed":25,"user":{"displayName":"Ki·ªát Tr·∫ßn","userId":"13976749715371674650"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2022 NVIDIA Corporation\n","Built on Wed_Sep_21_10:33:58_PDT_2022\n","Cuda compilation tools, release 11.8, V11.8.89\n","Build cuda_11.8.r11.8/compiler.31833905_0\n","gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n","Copyright (C) 2021 Free Software Foundation, Inc.\n","This is free software; see the source for copying conditions.  There is NO\n","warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n","\n"]}],"source":["# Check nvcc version\n","!nvcc -V\n","# Check GCC version\n","!gcc --version"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gkGnB9WyHSXB","outputId":"bd099af0-5b4f-462f-a2c9-8a0a988768ba","executionInfo":{"status":"ok","timestamp":1691419943681,"user_tz":-420,"elapsed":44212,"user":{"displayName":"Ki·ªát Tr·∫ßn","userId":"13976749715371674650"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openmim in /usr/local/lib/python3.10/dist-packages (0.3.9)\n","Requirement already satisfied: Click in /usr/local/lib/python3.10/dist-packages (from openmim) (8.1.6)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from openmim) (0.4.6)\n","Requirement already satisfied: model-index in /usr/local/lib/python3.10/dist-packages (from openmim) (0.1.11)\n","Requirement already satisfied: opendatalab in /usr/local/lib/python3.10/dist-packages (from openmim) (0.0.10)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from openmim) (1.5.3)\n","Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.10/dist-packages (from openmim) (23.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openmim) (2.28.2)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim) (13.4.2)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim) (0.9.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (6.0.1)\n","Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (3.4.4)\n","Requirement already satisfied: ordered-set in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (4.1.0)\n","Requirement already satisfied: pycryptodome in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim) (3.18.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim) (4.65.0)\n","Requirement already satisfied: openxlab in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim) (0.0.17)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2023.3)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (1.22.4)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (2.14.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->openmim) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->openmim) (1.16.0)\n","Requirement already satisfied: oss2~=2.17.0 in /usr/local/lib/python3.10/dist-packages (from openxlab->opendatalab->openmim) (2.17.0)\n","Requirement already satisfied: setuptools~=60.2.0 in /usr/local/lib/python3.10/dist-packages (from openxlab->opendatalab->openmim) (60.2.0)\n","Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.10/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (1.7)\n","Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (2.16.1)\n","Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /usr/local/lib/python3.10/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (2.13.36)\n","Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (0.10.0)\n","Requirement already satisfied: cryptography>=2.6.0 in /usr/lib/python3/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (3.4.8)\n","Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html\n","Requirement already satisfied: mmengine>=0.7.0 in /usr/local/lib/python3.10/dist-packages (0.8.4)\n","Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (2.4.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (1.22.4)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (6.0.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (13.4.2)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (2.3.0)\n","Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (0.40.1)\n","Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (4.7.0.72)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (4.41.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (3.1.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (2.8.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.7.0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.7.0) (2.14.0)\n","Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine>=0.7.0) (6.8.0)\n","Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine>=0.7.0) (3.9.1)\n","Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine>=0.7.0) (2.0.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmengine>=0.7.0) (3.16.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.7.0) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.7.0) (1.16.0)\n","Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html\n","Requirement already satisfied: mmcv>=2.0.0rc4 in /usr/local/lib/python3.10/dist-packages (2.0.1)\n","Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc4) (2.4.0)\n","Requirement already satisfied: mmengine>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc4) (0.8.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc4) (1.22.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc4) (23.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc4) (9.4.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc4) (6.0.1)\n","Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc4) (0.40.1)\n","Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc4) (4.7.0.72)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc4) (3.7.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc4) (13.4.2)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc4) (2.3.0)\n","Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0rc4) (6.8.0)\n","Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0rc4) (3.9.1)\n","Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0rc4) (2.0.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv>=2.0.0rc4) (3.16.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (4.41.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (3.1.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (2.8.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv>=2.0.0rc4) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv>=2.0.0rc4) (2.14.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv>=2.0.0rc4) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (1.16.0)\n","Cloning into 'mmdetection'...\n","remote: Enumerating objects: 36801, done.\u001b[K\n","remote: Counting objects: 100% (291/291), done.\u001b[K\n","remote: Compressing objects: 100% (211/211), done.\u001b[K\n","remote: Total 36801 (delta 108), reused 212 (delta 79), pack-reused 36510\u001b[K\n","Receiving objects: 100% (36801/36801), 57.00 MiB | 14.67 MiB/s, done.\n","Resolving deltas: 100% (25787/25787), done.\n","/content/mmdetection\n","Obtaining file:///content/mmdetection\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmdet==3.1.0) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmdet==3.1.0) (1.22.4)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmdet==3.1.0) (2.0.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmdet==3.1.0) (1.10.1)\n","Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from mmdet==3.1.0) (2.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmdet==3.1.0) (1.16.0)\n","Requirement already satisfied: terminaltables in /usr/local/lib/python3.10/dist-packages (from mmdet==3.1.0) (3.1.10)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.1.0) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.1.0) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.1.0) (4.41.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.1.0) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.1.0) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.1.0) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.1.0) (3.1.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.1.0) (2.8.2)\n","Installing collected packages: mmdet\n","  Running setup.py develop for mmdet\n","Successfully installed mmdet-3.1.0\n"]}],"source":["# install dependencies: (use cu111 because colab has CUDA 11.1)\n","%pip install -U openmim\n","!mim install \"mmengine>=0.7.0\"\n","!mim install \"mmcv>=2.0.0rc4\"\n","\n","# Install mmdetection\n","!rm -rf mmdetection\n","!git clone https://github.com/open-mmlab/mmdetection.git\n","%cd mmdetection\n","\n","%pip install -e ."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_YeUiqAoCaoV","outputId":"0ba37d89-4b0c-4d75-8131-f43d10bc32bd","executionInfo":{"status":"ok","timestamp":1691419946802,"user_tz":-420,"elapsed":3138,"user":{"displayName":"Ki·ªát Tr·∫ßn","userId":"13976749715371674650"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["sys.platform: linux\n","Python: 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n","CUDA available: True\n","numpy_random_seed: 2147483648\n","GPU 0: Tesla T4\n","CUDA_HOME: /usr/local/cuda\n","NVCC: Cuda compilation tools, release 11.8, V11.8.89\n","GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n","PyTorch: 2.0.1+cu118\n","PyTorch compiling details: PyTorch built with:\n","  - GCC 9.3\n","  - C++ Version: 201703\n","  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n","  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n","  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n","  - LAPACK is enabled (usually provided by MKL)\n","  - NNPACK is enabled\n","  - CPU capability usage: AVX2\n","  - CUDA Runtime 11.8\n","  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n","  - CuDNN 8.7\n","  - Magma 2.6.1\n","  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n","\n","TorchVision: 0.15.2+cu118\n","OpenCV: 4.7.0\n","MMEngine: 0.8.4\n","MMDetection: 3.1.0+f78af77\n"]}],"source":["from mmengine.utils import get_git_hash\n","from mmengine.utils.dl_utils import collect_env as collect_base_env\n","\n","import mmdet\n","\n","\n","def collect_env():\n","    \"\"\"Collect the information of the running environments.\"\"\"\n","    env_info = collect_base_env()\n","    env_info['MMDetection'] = f'{mmdet.__version__}+{get_git_hash()[:7]}'\n","    return env_info\n","\n","\n","if __name__ == '__main__':\n","    for name, val in collect_env().items():\n","        print(f'{name}: {val}')"]},{"cell_type":"markdown","metadata":{"id":"s99mDGBG1S1z"},"source":["### An efficient Real-Time one-stage detector\n","\n","In this tutorial, we use RTMDet, an efficient Real-Time one-stage detector as an example.\n","\n","The high-level architecture of RTMDet is shown in the following picture. More details can be found in the [paper](https://arxiv.org/abs/2212.07784).\n","\n","![RTMDet](https://user-images.githubusercontent.com/27466624/225922103-404064c1-3cb0-4ab5-9388-79f9517dcdb0.jpg)\n","\n","To obtain a more efficient model architecture, MMDetection explore an architecture that has compatible capacities in the backbone and neck, constructed by a basic building block that consists of large-kernel depth-wise convolutions. MMDetection further introduce soft labels when calculating matching costs in the dynamic label assignment to improve accuracy. Together with better training techniques, the resulting object detector, named RTMDet, achieves 52.8% AP on COCO with 300+ FPS on an NVIDIA 3090 GPU, outperforming the current mainstream industrial detectors. RTMDet achieves the best parameter-accuracy trade-off with tiny/small/medium/large/extra-large model sizes for various application scenarios, and obtains new state-of-the-art performance on real-time instance segmentation and rotated object detection. We hope the experimental results can provide new insights into designing versatile real-time object detectors for many object recognition tasks.\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j4doHX4exvS1","outputId":"7282c2b2-9a5d-495e-b4ac-d4a42eec50a9","executionInfo":{"status":"ok","timestamp":1691419952954,"user_tz":-420,"elapsed":6158,"user":{"displayName":"Ki·ªát Tr·∫ßn","userId":"13976749715371674650"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["processing rtmdet_tiny_8xb32-300e_coco...\n","\u001b[2Kdownloading \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.9/54.9 MiB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[32mSuccessfully downloaded rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth to /content/mmdetection/checkpoints\u001b[0m\n","\u001b[32mSuccessfully dumped rtmdet_tiny_8xb32-300e_coco.py to /content/mmdetection/checkpoints\u001b[0m\n"]}],"source":["# We download the pre-trained checkpoints for inference and finetuning.\n","!mkdir ./checkpoints\n","!mim download mmdet --config rtmdet_tiny_8xb32-300e_coco --dest ./checkpoints"]},{"cell_type":"markdown","metadata":{"id":"7GrWIJywLV-V"},"source":["## Train with customized datasets\n","\n","In this part, you will know how to train predefined models with customized datasets and then test it. We use the [balloon dataset](https://github.com/matterport/Mask_RCNN/tree/master/samples/balloon) as an example to describe the whole process.\n","\n","The basic steps are as below:\n","\n","1. Prepare the customized dataset\n","2. Prepare a config\n","3. Train, test, and infer models on the customized dataset.\n"]},{"cell_type":"markdown","metadata":{"id":"E73y5Lru-wBx"},"source":["### Prepare the customized dataset\n","\n","There are three ways to support a new dataset in MMDetection:\n","\n","1. Reorganize the dataset into COCO format.\n","2. Reorganize the dataset into a middle format.\n","3. Implement a new dataset.\n","\n","Usually, we recommend using the first two methods which are usually easier than the third.\n","\n","In this tutorial, we use the ballon dataset an example of converting the data into COCO format.\n","\n","**Note**: Datasets and metrics have been decoupled except CityScapes since MMDetection 3.0. Therefore, users can use any kind of evaluation metrics for any format of datasets during validation. For example: evaluate on COCO dataset with VOC metric, or evaluate on OpenImages dataset with both VOC and COCO metrics."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"fXEC6DWTXJT2","outputId":"38e36e1e-8846-4a45-b5d8-00d86906eba7","executionInfo":{"status":"ok","timestamp":1691419973288,"user_tz":-420,"elapsed":20387,"user":{"displayName":"Ki·ªát Tr·∫ßn","userId":"13976749715371674650"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-15ab521f-bc69-4655-b948-3c7de8911182\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-15ab521f-bc69-4655-b948-3c7de8911182\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle.json to kaggle.json\n","User uploaded file \"kaggle.json\" with length 62 bytes\n"]}],"source":["from google.colab import files\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))\n","\n","# Then move kaggle.json into the folder where the API expects to find it.\n","!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sbJhEsckU8UX","outputId":"b998868e-bba1-41b6-e0d8-7c9197c6d3c8","executionInfo":{"status":"ok","timestamp":1691419977631,"user_tz":-420,"elapsed":4355,"user":{"displayName":"Ki·ªát Tr·∫ßn","userId":"13976749715371674650"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading racoon-detection.zip to data\n"," 95% 12.0M/12.7M [00:01<00:00, 11.9MB/s]\n","100% 12.7M/12.7M [00:01<00:00, 7.84MB/s]\n"]}],"source":["# Download the data and unzip it\n","!kaggle datasets download -d debasisdotcom/racoon-detection -p data --unzip"]},{"cell_type":"markdown","metadata":{"id":"gmMpkzs2U8UY"},"source":["#### COCO annotation format\n","The necessary keys of COCO format for instance segmentation are as below, for the complete details, please refer [here](https://cocodataset.org/#format-data).\n","\n","```json\n","{\n","    \"images\": [image],\n","    \"annotations\": [annotation],\n","    \"categories\": [category]\n","}\n","image = {\n","    \"id\": int,\n","    \"width\": int,\n","    \"height\": int,\n","    \"file_name\": str,\n","}\n","annotation = {\n","    \"id\": int,\n","    \"image_id\": int,\n","    \"category_id\": int,\n","    \"segmentation\": RLE or [polygon],\n","    \"area\": float,\n","    \"bbox\": [x,y,width,height], # (x, y) are the coordinates of the upper left corner of the bbox\n","    \"iscrowd\": 0 or 1,\n","}\n","categories = [{\n","    \"id\": int,\n","    \"name\": str,\n","    \"supercategory\": str,\n","}]\n","```\n","\n","Assume we use the balloon dataset.\n","After downloading the data, we need to implement a function to convert the annotation format into the COCO format. Then we can use implemented `CocoDataset` to load the data and perform training and evaluation."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"7UlOF2Wkdoe5","executionInfo":{"status":"ok","timestamp":1691419977639,"user_tz":-420,"elapsed":116,"user":{"displayName":"Ki·ªát Tr·∫ßn","userId":"13976749715371674650"}}},"outputs":[],"source":["import pandas as pd\n","train = pd.read_csv(\"data/train_labels_.csv\")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"cTxpjh_Td2jb","outputId":"318393fb-6e29-4faa-ded0-aa9bb3241bff","executionInfo":{"status":"ok","timestamp":1691419977640,"user_tz":-420,"elapsed":116,"user":{"displayName":"Ki·ªát Tr·∫ßn","userId":"13976749715371674650"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["         filename  width  height    class  xmin  ymin  xmax  ymax\n","0  raccoon-17.jpg    259     194  raccoon    95    60   167   118\n","1  raccoon-11.jpg    660     432  raccoon     3     1   461   431\n","2  raccoon-63.jpg    600     400  raccoon    74   107   280   290\n","3  raccoon-63.jpg    600     400  raccoon   227    93   403   298\n","4  raccoon-60.jpg    273     185  raccoon    58    33   197   127"],"text/html":["\n","\n","  <div id=\"df-22816875-52a5-45db-96e0-c6e55f189276\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filename</th>\n","      <th>width</th>\n","      <th>height</th>\n","      <th>class</th>\n","      <th>xmin</th>\n","      <th>ymin</th>\n","      <th>xmax</th>\n","      <th>ymax</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>raccoon-17.jpg</td>\n","      <td>259</td>\n","      <td>194</td>\n","      <td>raccoon</td>\n","      <td>95</td>\n","      <td>60</td>\n","      <td>167</td>\n","      <td>118</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>raccoon-11.jpg</td>\n","      <td>660</td>\n","      <td>432</td>\n","      <td>raccoon</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>461</td>\n","      <td>431</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>raccoon-63.jpg</td>\n","      <td>600</td>\n","      <td>400</td>\n","      <td>raccoon</td>\n","      <td>74</td>\n","      <td>107</td>\n","      <td>280</td>\n","      <td>290</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>raccoon-63.jpg</td>\n","      <td>600</td>\n","      <td>400</td>\n","      <td>raccoon</td>\n","      <td>227</td>\n","      <td>93</td>\n","      <td>403</td>\n","      <td>298</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>raccoon-60.jpg</td>\n","      <td>273</td>\n","      <td>185</td>\n","      <td>raccoon</td>\n","      <td>58</td>\n","      <td>33</td>\n","      <td>197</td>\n","      <td>127</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22816875-52a5-45db-96e0-c6e55f189276')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-66dffabf-5398-4463-bbe6-561467569cfe\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-66dffabf-5398-4463-bbe6-561467569cfe')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-66dffabf-5398-4463-bbe6-561467569cfe button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-22816875-52a5-45db-96e0-c6e55f189276 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-22816875-52a5-45db-96e0-c6e55f189276');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":8}],"source":["train.head()"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"EDmjlpUBiaIL","executionInfo":{"status":"ok","timestamp":1691419977641,"user_tz":-420,"elapsed":114,"user":{"displayName":"Ki·ªát Tr·∫ßn","userId":"13976749715371674650"}}},"outputs":[],"source":["column_names =['filename','class','width', 'height','xmin','ymin','xmax','ymax']"]},{"cell_type":"code","source":["#Convert .csv format to COCO format\n","import numpy as np\n","import json\n","import pandas as pd\n","\n","path = '/content/mmdetection/data/train_labels_.csv' # the path to the CSV file\n","save_json_path = './data/traincoco.json'\n","\n","\n","data = pd.read_csv(path)\n","\n","images = []\n","categories = []\n","annotations = []\n","\n","category = {}\n","category[\"supercategory\"] = 'none'\n","category[\"id\"] = 0\n","category[\"name\"] = 'None'\n","categories.append(category)\n","\n","data['fileid'] = data['filename'].astype('category').cat.codes\n","data['categoryid']= pd.Categorical(data['class'],ordered= True).codes\n","data['categoryid'] = data['categoryid']+1\n","data['annid'] = data.index\n","\n","def image(row):\n","    image = {}\n","    image[\"height\"] = row.height\n","    image[\"width\"] = row.width\n","    image[\"id\"] = row.fileid\n","    image[\"file_name\"] = row.filename\n","    return image\n","\n","def category(row):\n","    category = {}\n","    category[\"supercategory\"] = 'None'\n","    category[\"id\"] = row.categoryid\n","    category[\"name\"] = row[2]\n","    return category\n","\n","def annotation(row):\n","    annotation = {}\n","    area = (row.xmax -row.xmin)*(row.ymax - row.ymin)\n","    annotation[\"segmentation\"] = []\n","    annotation[\"iscrowd\"] = 0\n","    annotation[\"area\"] = area\n","    annotation[\"image_id\"] = row.fileid\n","\n","    annotation[\"bbox\"] = [row.xmin, row.ymin, row.xmax -row.xmin,row.ymax-row.ymin ]\n","\n","    annotation[\"category_id\"] = 0\n","    annotation[\"id\"] = row.annid\n","    return annotation\n","\n","for row in data.itertuples():\n","    annotations.append(annotation(row))\n","\n","imagedf = data.drop_duplicates(subset=['fileid']).sort_values(by='fileid')\n","for row in imagedf.itertuples():\n","    images.append(image(row))\n","\n","catdf = data.drop_duplicates(subset=['categoryid']).sort_values(by='categoryid')\n","for row in catdf.itertuples():\n","    categories.append(category(row))\n","\n","data_coco = {}\n","data_coco[\"images\"] = images\n","data_coco[\"annotations\"] = annotations\n","data_coco[\"categories\"] = [{\n","            'id': 0,\n","            'name': 'raccoon'\n","        }]\n","json.dump(data_coco, open(save_json_path, \"w\"), indent=4)"],"metadata":{"id":"0-hHe-vCk8_j","executionInfo":{"status":"ok","timestamp":1691419977642,"user_tz":-420,"elapsed":114,"user":{"displayName":"Ki·ªát Tr·∫ßn","userId":"13976749715371674650"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yc9UDp1vU8UZ"},"source":["## Prepare a config\n","\n","The second step is to prepare a config thus the dataset could be successfully loaded. Assume that we want to use RTMDet-tiny, the config to train the detector on balloon dataset is as below. Assume the config is under directory `configs/rtmdet/` and named as `rtmdet_tiny_1xb4-20e_balloon.py`, the config is as below.\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"XjTW6XydU8Ua","executionInfo":{"status":"ok","timestamp":1691419977642,"user_tz":-420,"elapsed":113,"user":{"displayName":"Ki·ªát Tr·∫ßn","userId":"13976749715371674650"}}},"outputs":[],"source":["# T√¨m hi·ªÉu th√¥ng s·ªë c·∫•u h√¨nh, √Ω nghƒ©a c√°c ƒë·∫°i l∆∞·ª£ng.\n","config_raccoon = \"\"\"\n","# Inherit and overwrite part of the config based on this config\n","_base_ = './rtmdet_tiny_8xb32-300e_coco.py'\n","\n","data_root = './data/' # dataset root\n","\n","train_batch_size_per_gpu = 4\n","train_num_workers = 2\n","\n","max_epochs = 20\n","stage2_num_epochs = 1\n","base_lr = 0.00008\n","\n","\n","metainfo = {\n","    'classes': ('raccoon', ),\n","    'palette': [\n","        (220, 20, 60),\n","    ]\n","}\n","\n","train_dataloader = dict(\n","    batch_size=train_batch_size_per_gpu,\n","    num_workers=train_num_workers,\n","    dataset=dict(\n","        data_root=data_root,\n","        metainfo=metainfo,\n","        data_prefix=dict(img='/content/mmdetection/data/Racoon Images/images/'),\n","        ann_file='/content/mmdetection/data/traincoco.json'))\n","\n","val_dataloader = dict(\n","    dataset=dict(\n","        data_root=data_root,\n","        metainfo=metainfo,\n","        data_prefix=dict(img='/content/mmdetection/data/Racoon Images/images/'),\n","        ann_file='/content/mmdetection/data/traincoco.json'))\n","\n","test_dataloader = val_dataloader\n","\n","val_evaluator = dict(ann_file=data_root + 'traincoco.json')\n","\n","test_evaluator = val_evaluator\n","\n","model = dict(bbox_head=dict(num_classes=1))\n","\n","# learning rate\n","param_scheduler = [\n","    dict(\n","        type='LinearLR',\n","        start_factor=1.0e-5,\n","        by_epoch=False,\n","        begin=0,\n","        end=10),\n","    dict(\n","        # use cosine lr from 10 to 20 epoch\n","        type='CosineAnnealingLR',\n","        eta_min=base_lr * 0.05,\n","        begin=max_epochs // 2,\n","        end=max_epochs,\n","        T_max=max_epochs // 2,\n","        by_epoch=True,\n","        convert_to_iter_based=True),\n","]\n","\n","train_pipeline_stage2 = [\n","    dict(type='LoadImageFromFile', backend_args=None),\n","    dict(type='LoadAnnotations', with_bbox=True),\n","    dict(\n","        type='RandomResize',\n","        scale=(640, 640),\n","        ratio_range=(0.1, 2.0),\n","        keep_ratio=True),\n","    dict(type='RandomCrop', crop_size=(640, 640)),\n","    dict(type='YOLOXHSVRandomAug'),\n","    dict(type='RandomFlip', prob=0.5),\n","    dict(type='Pad', size=(640, 640), pad_val=dict(img=(114, 114, 114))),\n","    dict(type='PackDetInputs')\n","]\n","\n","# optimizer\n","optim_wrapper = dict(\n","    _delete_=True,\n","    type='OptimWrapper',\n","    optimizer=dict(type='AdamW', lr=base_lr, weight_decay=0.05),\n","    paramwise_cfg=dict(\n","        norm_decay_mult=0, bias_decay_mult=0, bypass_duplicate=True))\n","\n","default_hooks = dict(\n","    checkpoint=dict(\n","        interval=5,\n","        max_keep_ckpts=2,  # only keep latest 2 checkpoints\n","        save_best='auto'\n","    ),\n","    logger=dict(type='LoggerHook', interval=5))\n","\n","custom_hooks = [\n","    dict(\n","        type='PipelineSwitchHook',\n","        switch_epoch=max_epochs - stage2_num_epochs,\n","        switch_pipeline=train_pipeline_stage2)\n","]\n","\n","# load COCO pre-trained weight\n","load_from = './checkpoints/rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth'\n","\n","train_cfg = dict(type='EpochBasedTrainLoop', max_epochs=max_epochs, val_interval=1)\n","visualizer = dict(vis_backends=[dict(type='LocalVisBackend'),dict(type='TensorboardVisBackend')])\n","\"\"\"\n","\n","with open('./configs/rtmdet/rtmdet_tiny_1xb4-20e_raccoon.py', 'w') as f:\n","    f.write(config_raccoon)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5LNm7LxwZG2w","outputId":"350a00d8-c3aa-4d8a-bcc5-8390157b9ca6","executionInfo":{"status":"ok","timestamp":1691420088552,"user_tz":-420,"elapsed":111022,"user":{"displayName":"Ki·ªát Tr·∫ßn","userId":"13976749715371674650"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["08/07 14:53:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n","------------------------------------------------------------\n","System environment:\n","    sys.platform: linux\n","    Python: 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n","    CUDA available: True\n","    numpy_random_seed: 1529258372\n","    GPU 0: Tesla T4\n","    CUDA_HOME: /usr/local/cuda\n","    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n","    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n","    PyTorch: 2.0.1+cu118\n","    PyTorch compiling details: PyTorch built with:\n","  - GCC 9.3\n","  - C++ Version: 201703\n","  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n","  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n","  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n","  - LAPACK is enabled (usually provided by MKL)\n","  - NNPACK is enabled\n","  - CPU capability usage: AVX2\n","  - CUDA Runtime 11.8\n","  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n","  - CuDNN 8.7\n","  - Magma 2.6.1\n","  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n","\n","    TorchVision: 0.15.2+cu118\n","    OpenCV: 4.7.0\n","    MMEngine: 0.8.4\n","\n","Runtime environment:\n","    cudnn_benchmark: False\n","    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n","    dist_cfg: {'backend': 'nccl'}\n","    seed: 1529258372\n","    Distributed launcher: none\n","    Distributed training: False\n","    GPU number: 1\n","------------------------------------------------------------\n","\n","08/07 14:53:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n","auto_scale_lr = dict(base_batch_size=16, enable=False)\n","backend_args = None\n","base_lr = 8e-05\n","checkpoint = 'https://download.openmmlab.com/mmdetection/v3.0/rtmdet/cspnext_rsb_pretrain/cspnext-tiny_imagenet_600e.pth'\n","custom_hooks = [\n","    dict(\n","        switch_epoch=19,\n","        switch_pipeline=[\n","            dict(backend_args=None, type='LoadImageFromFile'),\n","            dict(type='LoadAnnotations', with_bbox=True),\n","            dict(\n","                keep_ratio=True,\n","                ratio_range=(\n","                    0.1,\n","                    2.0,\n","                ),\n","                scale=(\n","                    640,\n","                    640,\n","                ),\n","                type='RandomResize'),\n","            dict(crop_size=(\n","                640,\n","                640,\n","            ), type='RandomCrop'),\n","            dict(type='YOLOXHSVRandomAug'),\n","            dict(prob=0.5, type='RandomFlip'),\n","            dict(\n","                pad_val=dict(img=(\n","                    114,\n","                    114,\n","                    114,\n","                )),\n","                size=(\n","                    640,\n","                    640,\n","                ),\n","                type='Pad'),\n","            dict(type='PackDetInputs'),\n","        ],\n","        type='PipelineSwitchHook'),\n","]\n","data_root = './data/'\n","dataset_type = 'CocoDataset'\n","default_hooks = dict(\n","    checkpoint=dict(\n","        interval=5, max_keep_ckpts=2, save_best='auto', type='CheckpointHook'),\n","    logger=dict(interval=5, type='LoggerHook'),\n","    param_scheduler=dict(type='ParamSchedulerHook'),\n","    sampler_seed=dict(type='DistSamplerSeedHook'),\n","    timer=dict(type='IterTimerHook'),\n","    visualization=dict(type='DetVisualizationHook'))\n","default_scope = 'mmdet'\n","env_cfg = dict(\n","    cudnn_benchmark=False,\n","    dist_cfg=dict(backend='nccl'),\n","    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n","img_scales = [\n","    (\n","        640,\n","        640,\n","    ),\n","    (\n","        320,\n","        320,\n","    ),\n","    (\n","        960,\n","        960,\n","    ),\n","]\n","interval = 10\n","launcher = 'none'\n","load_from = './checkpoints/rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth'\n","log_level = 'INFO'\n","log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n","max_epochs = 20\n","metainfo = dict(\n","    classes=('raccoon', ), palette=[\n","        (\n","            220,\n","            20,\n","            60,\n","        ),\n","    ])\n","model = dict(\n","    backbone=dict(\n","        act_cfg=dict(inplace=True, type='SiLU'),\n","        arch='P5',\n","        channel_attention=True,\n","        deepen_factor=0.167,\n","        expand_ratio=0.5,\n","        init_cfg=dict(\n","            checkpoint=\n","            'https://download.openmmlab.com/mmdetection/v3.0/rtmdet/cspnext_rsb_pretrain/cspnext-tiny_imagenet_600e.pth',\n","            prefix='backbone.',\n","            type='Pretrained'),\n","        norm_cfg=dict(type='SyncBN'),\n","        type='CSPNeXt',\n","        widen_factor=0.375),\n","    bbox_head=dict(\n","        act_cfg=dict(inplace=True, type='SiLU'),\n","        anchor_generator=dict(\n","            offset=0, strides=[\n","                8,\n","                16,\n","                32,\n","            ], type='MlvlPointGenerator'),\n","        bbox_coder=dict(type='DistancePointBBoxCoder'),\n","        exp_on_reg=False,\n","        feat_channels=96,\n","        in_channels=96,\n","        loss_bbox=dict(loss_weight=2.0, type='GIoULoss'),\n","        loss_cls=dict(\n","            beta=2.0,\n","            loss_weight=1.0,\n","            type='QualityFocalLoss',\n","            use_sigmoid=True),\n","        norm_cfg=dict(type='SyncBN'),\n","        num_classes=1,\n","        pred_kernel_size=1,\n","        share_conv=True,\n","        stacked_convs=2,\n","        type='RTMDetSepBNHead',\n","        with_objectness=False),\n","    data_preprocessor=dict(\n","        batch_augments=None,\n","        bgr_to_rgb=False,\n","        mean=[\n","            103.53,\n","            116.28,\n","            123.675,\n","        ],\n","        std=[\n","            57.375,\n","            57.12,\n","            58.395,\n","        ],\n","        type='DetDataPreprocessor'),\n","    neck=dict(\n","        act_cfg=dict(inplace=True, type='SiLU'),\n","        expand_ratio=0.5,\n","        in_channels=[\n","            96,\n","            192,\n","            384,\n","        ],\n","        norm_cfg=dict(type='SyncBN'),\n","        num_csp_blocks=1,\n","        out_channels=96,\n","        type='CSPNeXtPAFPN'),\n","    test_cfg=dict(\n","        max_per_img=300,\n","        min_bbox_size=0,\n","        nms=dict(iou_threshold=0.65, type='nms'),\n","        nms_pre=30000,\n","        score_thr=0.001),\n","    train_cfg=dict(\n","        allowed_border=-1,\n","        assigner=dict(topk=13, type='DynamicSoftLabelAssigner'),\n","        debug=False,\n","        pos_weight=-1),\n","    type='RTMDet')\n","optim_wrapper = dict(\n","    optimizer=dict(lr=8e-05, type='AdamW', weight_decay=0.05),\n","    paramwise_cfg=dict(\n","        bias_decay_mult=0, bypass_duplicate=True, norm_decay_mult=0),\n","    type='OptimWrapper')\n","param_scheduler = [\n","    dict(begin=0, by_epoch=False, end=10, start_factor=1e-05, type='LinearLR'),\n","    dict(\n","        T_max=10,\n","        begin=10,\n","        by_epoch=True,\n","        convert_to_iter_based=True,\n","        end=20,\n","        eta_min=4.000000000000001e-06,\n","        type='CosineAnnealingLR'),\n","]\n","resume = False\n","stage2_num_epochs = 1\n","test_cfg = dict(type='TestLoop')\n","test_dataloader = dict(\n","    batch_size=5,\n","    dataset=dict(\n","        ann_file='/content/mmdetection/data/traincoco.json',\n","        backend_args=None,\n","        data_prefix=dict(\n","            img='/content/mmdetection/data/Racoon Images/images/'),\n","        data_root='./data/',\n","        metainfo=dict(classes=('raccoon', ), palette=[\n","            (\n","                220,\n","                20,\n","                60,\n","            ),\n","        ]),\n","        pipeline=[\n","            dict(backend_args=None, type='LoadImageFromFile'),\n","            dict(keep_ratio=True, scale=(\n","                640,\n","                640,\n","            ), type='Resize'),\n","            dict(\n","                pad_val=dict(img=(\n","                    114,\n","                    114,\n","                    114,\n","                )),\n","                size=(\n","                    640,\n","                    640,\n","                ),\n","                type='Pad'),\n","            dict(type='LoadAnnotations', with_bbox=True),\n","            dict(\n","                meta_keys=(\n","                    'img_id',\n","                    'img_path',\n","                    'ori_shape',\n","                    'img_shape',\n","                    'scale_factor',\n","                ),\n","                type='PackDetInputs'),\n","        ],\n","        test_mode=True,\n","        type='CocoDataset'),\n","    drop_last=False,\n","    num_workers=10,\n","    persistent_workers=True,\n","    sampler=dict(shuffle=False, type='DefaultSampler'))\n","test_evaluator = dict(\n","    ann_file='./data/traincoco.json',\n","    backend_args=None,\n","    format_only=False,\n","    metric='bbox',\n","    proposal_nums=(\n","        100,\n","        1,\n","        10,\n","    ),\n","    type='CocoMetric')\n","test_pipeline = [\n","    dict(backend_args=None, type='LoadImageFromFile'),\n","    dict(keep_ratio=True, scale=(\n","        640,\n","        640,\n","    ), type='Resize'),\n","    dict(pad_val=dict(img=(\n","        114,\n","        114,\n","        114,\n","    )), size=(\n","        640,\n","        640,\n","    ), type='Pad'),\n","    dict(type='LoadAnnotations', with_bbox=True),\n","    dict(\n","        meta_keys=(\n","            'img_id',\n","            'img_path',\n","            'ori_shape',\n","            'img_shape',\n","            'scale_factor',\n","        ),\n","        type='PackDetInputs'),\n","]\n","train_batch_size_per_gpu = 4\n","train_cfg = dict(\n","    dynamic_intervals=[\n","        (\n","            280,\n","            1,\n","        ),\n","    ],\n","    max_epochs=20,\n","    type='EpochBasedTrainLoop',\n","    val_interval=1)\n","train_dataloader = dict(\n","    batch_sampler=None,\n","    batch_size=4,\n","    dataset=dict(\n","        ann_file='/content/mmdetection/data/traincoco.json',\n","        backend_args=None,\n","        data_prefix=dict(\n","            img='/content/mmdetection/data/Racoon Images/images/'),\n","        data_root='./data/',\n","        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n","        metainfo=dict(classes=('raccoon', ), palette=[\n","            (\n","                220,\n","                20,\n","                60,\n","            ),\n","        ]),\n","        pipeline=[\n","            dict(backend_args=None, type='LoadImageFromFile'),\n","            dict(type='LoadAnnotations', with_bbox=True),\n","            dict(\n","                img_scale=(\n","                    640,\n","                    640,\n","                ),\n","                max_cached_images=20,\n","                pad_val=114.0,\n","                random_pop=False,\n","                type='CachedMosaic'),\n","            dict(\n","                keep_ratio=True,\n","                ratio_range=(\n","                    0.5,\n","                    2.0,\n","                ),\n","                scale=(\n","                    1280,\n","                    1280,\n","                ),\n","                type='RandomResize'),\n","            dict(crop_size=(\n","                640,\n","                640,\n","            ), type='RandomCrop'),\n","            dict(type='YOLOXHSVRandomAug'),\n","            dict(prob=0.5, type='RandomFlip'),\n","            dict(\n","                pad_val=dict(img=(\n","                    114,\n","                    114,\n","                    114,\n","                )),\n","                size=(\n","                    640,\n","                    640,\n","                ),\n","                type='Pad'),\n","            dict(\n","                img_scale=(\n","                    640,\n","                    640,\n","                ),\n","                max_cached_images=10,\n","                pad_val=(\n","                    114,\n","                    114,\n","                    114,\n","                ),\n","                prob=0.5,\n","                random_pop=False,\n","                ratio_range=(\n","                    1.0,\n","                    1.0,\n","                ),\n","                type='CachedMixUp'),\n","            dict(type='PackDetInputs'),\n","        ],\n","        type='CocoDataset'),\n","    num_workers=2,\n","    persistent_workers=True,\n","    pin_memory=True,\n","    sampler=dict(shuffle=True, type='DefaultSampler'))\n","train_num_workers = 2\n","train_pipeline = [\n","    dict(backend_args=None, type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations', with_bbox=True),\n","    dict(\n","        img_scale=(\n","            640,\n","            640,\n","        ),\n","        max_cached_images=20,\n","        pad_val=114.0,\n","        random_pop=False,\n","        type='CachedMosaic'),\n","    dict(\n","        keep_ratio=True,\n","        ratio_range=(\n","            0.5,\n","            2.0,\n","        ),\n","        scale=(\n","            1280,\n","            1280,\n","        ),\n","        type='RandomResize'),\n","    dict(crop_size=(\n","        640,\n","        640,\n","    ), type='RandomCrop'),\n","    dict(type='YOLOXHSVRandomAug'),\n","    dict(prob=0.5, type='RandomFlip'),\n","    dict(pad_val=dict(img=(\n","        114,\n","        114,\n","        114,\n","    )), size=(\n","        640,\n","        640,\n","    ), type='Pad'),\n","    dict(\n","        img_scale=(\n","            640,\n","            640,\n","        ),\n","        max_cached_images=10,\n","        pad_val=(\n","            114,\n","            114,\n","            114,\n","        ),\n","        prob=0.5,\n","        random_pop=False,\n","        ratio_range=(\n","            1.0,\n","            1.0,\n","        ),\n","        type='CachedMixUp'),\n","    dict(type='PackDetInputs'),\n","]\n","train_pipeline_stage2 = [\n","    dict(backend_args=None, type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations', with_bbox=True),\n","    dict(\n","        keep_ratio=True,\n","        ratio_range=(\n","            0.1,\n","            2.0,\n","        ),\n","        scale=(\n","            640,\n","            640,\n","        ),\n","        type='RandomResize'),\n","    dict(crop_size=(\n","        640,\n","        640,\n","    ), type='RandomCrop'),\n","    dict(type='YOLOXHSVRandomAug'),\n","    dict(prob=0.5, type='RandomFlip'),\n","    dict(pad_val=dict(img=(\n","        114,\n","        114,\n","        114,\n","    )), size=(\n","        640,\n","        640,\n","    ), type='Pad'),\n","    dict(type='PackDetInputs'),\n","]\n","tta_model = dict(\n","    tta_cfg=dict(max_per_img=100, nms=dict(iou_threshold=0.6, type='nms')),\n","    type='DetTTAModel')\n","tta_pipeline = [\n","    dict(backend_args=None, type='LoadImageFromFile'),\n","    dict(\n","        transforms=[\n","            [\n","                dict(keep_ratio=True, scale=(\n","                    640,\n","                    640,\n","                ), type='Resize'),\n","                dict(keep_ratio=True, scale=(\n","                    320,\n","                    320,\n","                ), type='Resize'),\n","                dict(keep_ratio=True, scale=(\n","                    960,\n","                    960,\n","                ), type='Resize'),\n","            ],\n","            [\n","                dict(prob=1.0, type='RandomFlip'),\n","                dict(prob=0.0, type='RandomFlip'),\n","            ],\n","            [\n","                dict(\n","                    pad_val=dict(img=(\n","                        114,\n","                        114,\n","                        114,\n","                    )),\n","                    size=(\n","                        960,\n","                        960,\n","                    ),\n","                    type='Pad'),\n","            ],\n","            [\n","                dict(type='LoadAnnotations', with_bbox=True),\n","            ],\n","            [\n","                dict(\n","                    meta_keys=(\n","                        'img_id',\n","                        'img_path',\n","                        'ori_shape',\n","                        'img_shape',\n","                        'scale_factor',\n","                        'flip',\n","                        'flip_direction',\n","                    ),\n","                    type='PackDetInputs'),\n","            ],\n","        ],\n","        type='TestTimeAug'),\n","]\n","val_cfg = dict(type='ValLoop')\n","val_dataloader = dict(\n","    batch_size=5,\n","    dataset=dict(\n","        ann_file='/content/mmdetection/data/traincoco.json',\n","        backend_args=None,\n","        data_prefix=dict(\n","            img='/content/mmdetection/data/Racoon Images/images/'),\n","        data_root='./data/',\n","        metainfo=dict(classes=('raccoon', ), palette=[\n","            (\n","                220,\n","                20,\n","                60,\n","            ),\n","        ]),\n","        pipeline=[\n","            dict(backend_args=None, type='LoadImageFromFile'),\n","            dict(keep_ratio=True, scale=(\n","                640,\n","                640,\n","            ), type='Resize'),\n","            dict(\n","                pad_val=dict(img=(\n","                    114,\n","                    114,\n","                    114,\n","                )),\n","                size=(\n","                    640,\n","                    640,\n","                ),\n","                type='Pad'),\n","            dict(type='LoadAnnotations', with_bbox=True),\n","            dict(\n","                meta_keys=(\n","                    'img_id',\n","                    'img_path',\n","                    'ori_shape',\n","                    'img_shape',\n","                    'scale_factor',\n","                ),\n","                type='PackDetInputs'),\n","        ],\n","        test_mode=True,\n","        type='CocoDataset'),\n","    drop_last=False,\n","    num_workers=10,\n","    persistent_workers=True,\n","    sampler=dict(shuffle=False, type='DefaultSampler'))\n","val_evaluator = dict(\n","    ann_file='./data/traincoco.json',\n","    backend_args=None,\n","    format_only=False,\n","    metric='bbox',\n","    proposal_nums=(\n","        100,\n","        1,\n","        10,\n","    ),\n","    type='CocoMetric')\n","vis_backends = [\n","    dict(type='LocalVisBackend'),\n","]\n","visualizer = dict(\n","    name='visualizer',\n","    type='DetLocalVisualizer',\n","    vis_backends=[\n","        dict(type='LocalVisBackend'),\n","        dict(type='TensorboardVisBackend'),\n","    ])\n","work_dir = './work_dirs/rtmdet_tiny_1xb4-20e_raccoon'\n","\n","2023-08-07 14:53:05.683932: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-08-07 14:53:07.426868: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","08/07 14:53:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n","08/07 14:53:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n","before_run:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n","(BELOW_NORMAL) LoggerHook                         \n"," -------------------- \n","before_train:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n","(NORMAL      ) IterTimerHook                      \n","(VERY_LOW    ) CheckpointHook                     \n"," -------------------- \n","before_train_epoch:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n","(NORMAL      ) IterTimerHook                      \n","(NORMAL      ) DistSamplerSeedHook                \n","(NORMAL      ) PipelineSwitchHook                 \n"," -------------------- \n","before_train_iter:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n","(NORMAL      ) IterTimerHook                      \n"," -------------------- \n","after_train_iter:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n","(NORMAL      ) IterTimerHook                      \n","(BELOW_NORMAL) LoggerHook                         \n","(LOW         ) ParamSchedulerHook                 \n","(VERY_LOW    ) CheckpointHook                     \n"," -------------------- \n","after_train_epoch:\n","(NORMAL      ) IterTimerHook                      \n","(LOW         ) ParamSchedulerHook                 \n","(VERY_LOW    ) CheckpointHook                     \n"," -------------------- \n","before_val:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n"," -------------------- \n","before_val_epoch:\n","(NORMAL      ) IterTimerHook                      \n"," -------------------- \n","before_val_iter:\n","(NORMAL      ) IterTimerHook                      \n"," -------------------- \n","after_val_iter:\n","(NORMAL      ) IterTimerHook                      \n","(NORMAL      ) DetVisualizationHook               \n","(BELOW_NORMAL) LoggerHook                         \n"," -------------------- \n","after_val_epoch:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n","(NORMAL      ) IterTimerHook                      \n","(BELOW_NORMAL) LoggerHook                         \n","(LOW         ) ParamSchedulerHook                 \n","(VERY_LOW    ) CheckpointHook                     \n"," -------------------- \n","after_val:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n"," -------------------- \n","after_train:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n","(VERY_LOW    ) CheckpointHook                     \n"," -------------------- \n","before_test:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n"," -------------------- \n","before_test_epoch:\n","(NORMAL      ) IterTimerHook                      \n"," -------------------- \n","before_test_iter:\n","(NORMAL      ) IterTimerHook                      \n"," -------------------- \n","after_test_iter:\n","(NORMAL      ) IterTimerHook                      \n","(NORMAL      ) DetVisualizationHook               \n","(BELOW_NORMAL) LoggerHook                         \n"," -------------------- \n","after_test_epoch:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n","(NORMAL      ) IterTimerHook                      \n","(BELOW_NORMAL) LoggerHook                         \n"," -------------------- \n","after_test:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n"," -------------------- \n","after_run:\n","(BELOW_NORMAL) LoggerHook                         \n"," -------------------- \n","loading annotations into memory...\n","Done (t=0.00s)\n","creating index...\n","index created!\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.0.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.0.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.1.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.1.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.2.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.2.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.0.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.0.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.main_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.main_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.short_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.short_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.final_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.final_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv1.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv1.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.attention.fc.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.0.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.0.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.main_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.main_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.short_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.short_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.final_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.final_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv1.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv1.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.attention.fc.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.0.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.0.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.main_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.main_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.short_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.short_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.final_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.final_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv1.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv1.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.attention.fc.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.0.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.0.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.1.conv1.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.1.conv1.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.1.conv2.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.1.conv2.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.main_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.main_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.short_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.short_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.final_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.final_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv1.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv1.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.attention.fc.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.reduce_layers.0.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.reduce_layers.0.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.reduce_layers.1.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.reduce_layers.1.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.main_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.main_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.short_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.short_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.final_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.final_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv1.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv1.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.main_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.main_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.short_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.short_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.final_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.final_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv1.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv1.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.downsamples.0.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.downsamples.0.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.downsamples.1.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.downsamples.1.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.main_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.main_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.short_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.short_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.final_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.final_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv1.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv1.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.main_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.main_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.short_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.short_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.final_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.final_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv1.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv1.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_convs.0.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_convs.0.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_convs.1.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_convs.1.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_convs.2.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_convs.2.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.0.0.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.0.0.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.0.1.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.0.1.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.cls_convs.1.0.conv is duplicate. It is skipped since bypass_duplicate=True\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.1.0.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.1.0.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.cls_convs.1.1.conv is duplicate. It is skipped since bypass_duplicate=True\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.1.1.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.1.1.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.cls_convs.2.0.conv is duplicate. It is skipped since bypass_duplicate=True\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.2.0.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.2.0.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.cls_convs.2.1.conv is duplicate. It is skipped since bypass_duplicate=True\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.2.1.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.2.1.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.0.0.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.0.0.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.0.1.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.0.1.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.reg_convs.1.0.conv is duplicate. It is skipped since bypass_duplicate=True\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.1.0.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.1.0.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.reg_convs.1.1.conv is duplicate. It is skipped since bypass_duplicate=True\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.1.1.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.1.1.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.reg_convs.2.0.conv is duplicate. It is skipped since bypass_duplicate=True\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.2.0.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.2.0.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.reg_convs.2.1.conv is duplicate. It is skipped since bypass_duplicate=True\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.2.1.bn.weight:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.2.1.bn.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_cls.0.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_cls.1.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_cls.2.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_reg.0.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_reg.1.bias:weight_decay=0.0\n","08/07 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_reg.2.bias:weight_decay=0.0\n","loading annotations into memory...\n","Done (t=0.00s)\n","creating index...\n","index created!\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","loading annotations into memory...\n","Done (t=0.00s)\n","creating index...\n","index created!\n","08/07 14:53:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load backbone. in model from: https://download.openmmlab.com/mmdetection/v3.0/rtmdet/cspnext_rsb_pretrain/cspnext-tiny_imagenet_600e.pth\n","Loads checkpoint by http backend from path: https://download.openmmlab.com/mmdetection/v3.0/rtmdet/cspnext_rsb_pretrain/cspnext-tiny_imagenet_600e.pth\n","Downloading: \"https://download.openmmlab.com/mmdetection/v3.0/rtmdet/cspnext_rsb_pretrain/cspnext-tiny_imagenet_600e.pth\" to /root/.cache/torch/hub/checkpoints/cspnext-tiny_imagenet_600e.pth\n","100% 31.5M/31.5M [00:02<00:00, 13.0MB/s]\n","Loads checkpoint by local backend from path: ./checkpoints/rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth\n","The model and loaded state dict do not match exactly\n","\n","size mismatch for bbox_head.rtm_cls.0.weight: copying a param with shape torch.Size([80, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 96, 1, 1]).\n","size mismatch for bbox_head.rtm_cls.0.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).\n","size mismatch for bbox_head.rtm_cls.1.weight: copying a param with shape torch.Size([80, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 96, 1, 1]).\n","size mismatch for bbox_head.rtm_cls.1.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).\n","size mismatch for bbox_head.rtm_cls.2.weight: copying a param with shape torch.Size([80, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 96, 1, 1]).\n","size mismatch for bbox_head.rtm_cls.2.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).\n","unexpected key in source state_dict: data_preprocessor.mean, data_preprocessor.std\n","\n","08/07 14:53:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from ./checkpoints/rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth\n","08/07 14:53:16 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n","08/07 14:53:16 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n","08/07 14:53:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /content/mmdetection/work_dirs/rtmdet_tiny_1xb4-20e_raccoon.\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","08/07 14:53:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 5/40]  base_lr: 3.5556e-05 lr: 3.5556e-05  eta: 0:06:34  time: 0.4963  data_time: 0.0806  memory: 1422  loss: 2.5302  loss_cls: 1.7373  loss_bbox: 0.7929\n","08/07 14:53:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][10/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:05:37  time: 0.4276  data_time: 0.0460  memory: 1422  loss: 2.5435  loss_cls: 1.7671  loss_bbox: 0.7764\n","08/07 14:53:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][15/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:05:15  time: 0.4019  data_time: 0.0335  memory: 1422  loss: 2.5449  loss_cls: 1.7716  loss_bbox: 0.7733\n","08/07 14:53:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][20/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:05:10  time: 0.3980  data_time: 0.0271  memory: 1422  loss: 2.5335  loss_cls: 1.7586  loss_bbox: 0.7749\n","08/07 14:53:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][25/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:04:59  time: 0.3869  data_time: 0.0236  memory: 1422  loss: 2.5292  loss_cls: 1.7569  loss_bbox: 0.7722\n","08/07 14:53:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][30/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:04:33  time: 0.3557  data_time: 0.0209  memory: 1422  loss: 2.5311  loss_cls: 1.7608  loss_bbox: 0.7703\n","08/07 14:53:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][35/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:04:14  time: 0.3332  data_time: 0.0185  memory: 1422  loss: 2.5318  loss_cls: 1.7672  loss_bbox: 0.7645\n","08/07 14:53:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: rtmdet_tiny_1xb4-20e_raccoon_20230807_145300\n","08/07 14:53:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][40/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:03:56  time: 0.3115  data_time: 0.0165  memory: 1422  loss: 2.5238  loss_cls: 1.7590  loss_bbox: 0.7648\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","08/07 14:53:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][ 5/32]    eta: 0:00:06  time: 0.2500  data_time: 0.1619  memory: 325  \n","08/07 14:53:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][10/32]    eta: 0:00:03  time: 0.1540  data_time: 0.0820  memory: 325  \n","08/07 14:53:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][15/32]    eta: 0:00:02  time: 0.1247  data_time: 0.0587  memory: 325  \n","08/07 14:53:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][20/32]    eta: 0:00:01  time: 0.1076  data_time: 0.0443  memory: 325  \n","08/07 14:53:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][25/32]    eta: 0:00:00  time: 0.1026  data_time: 0.0379  memory: 325  \n","08/07 14:53:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][30/32]    eta: 0:00:00  time: 0.1002  data_time: 0.0341  memory: 325  \n","08/07 14:53:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n","Loading and preparing results...\n","DONE (t=0.05s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.86s).\n","Accumulating evaluation results...\n","DONE (t=0.14s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.006\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.005\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.371\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.246\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.381\n","08/07 14:53:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.002 0.006 0.002 -1.000 0.000 0.005\n","08/07 14:53:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][32/32]    coco/bbox_mAP: 0.0020  coco/bbox_mAP_50: 0.0060  coco/bbox_mAP_75: 0.0020  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0000  coco/bbox_mAP_l: 0.0050  data_time: 0.0326  time: 0.0991\n","08/07 14:53:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.0020 coco/bbox_mAP at 1 epoch is saved to best_coco_bbox_mAP_epoch_1.pth.\n","08/07 14:53:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 5/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:04:06  time: 0.3268  data_time: 0.0206  memory: 1422  loss: 2.5191  loss_cls: 1.7567  loss_bbox: 0.7624\n","08/07 14:53:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][10/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:04:06  time: 0.3286  data_time: 0.0191  memory: 1422  loss: 2.5129  loss_cls: 1.7537  loss_bbox: 0.7592\n","08/07 14:53:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][15/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:04:08  time: 0.3171  data_time: 0.0121  memory: 1422  loss: 2.5041  loss_cls: 1.7504  loss_bbox: 0.7537\n","08/07 14:53:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][20/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:04:17  time: 0.3328  data_time: 0.0124  memory: 1422  loss: 2.4979  loss_cls: 1.7487  loss_bbox: 0.7493\n","08/07 14:53:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][25/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:04:07  time: 0.3177  data_time: 0.0121  memory: 1422  loss: 2.4847  loss_cls: 1.7411  loss_bbox: 0.7436\n","08/07 14:53:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][30/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:04:00  time: 0.3019  data_time: 0.0121  memory: 1422  loss: 2.4719  loss_cls: 1.7374  loss_bbox: 0.7345\n","08/07 14:53:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][35/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:03:52  time: 0.2884  data_time: 0.0115  memory: 1422  loss: 2.4578  loss_cls: 1.7301  loss_bbox: 0.7277\n","08/07 14:53:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: rtmdet_tiny_1xb4-20e_raccoon_20230807_145300\n","08/07 14:53:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][40/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:03:44  time: 0.2847  data_time: 0.0112  memory: 1422  loss: 2.4359  loss_cls: 1.7199  loss_bbox: 0.7159\n","08/07 14:53:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][ 5/32]    eta: 0:00:04  time: 0.1091  data_time: 0.0413  memory: 325  \n","08/07 14:53:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][10/32]    eta: 0:00:02  time: 0.1031  data_time: 0.0366  memory: 325  \n","08/07 14:53:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][15/32]    eta: 0:00:01  time: 0.0992  data_time: 0.0340  memory: 325  \n","08/07 14:53:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][20/32]    eta: 0:00:01  time: 0.0785  data_time: 0.0174  memory: 325  \n","08/07 14:53:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][25/32]    eta: 0:00:00  time: 0.0776  data_time: 0.0169  memory: 325  \n","08/07 14:53:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][30/32]    eta: 0:00:00  time: 0.0780  data_time: 0.0178  memory: 325  \n","08/07 14:53:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n","Loading and preparing results...\n","DONE (t=0.35s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.80s).\n","Accumulating evaluation results...\n","DONE (t=0.14s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.011\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.024\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.016\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.006\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.072\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.583\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.438\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.595\n","08/07 14:53:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.011 0.024 0.007 -1.000 0.002 0.016\n","08/07 14:53:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [2][32/32]    coco/bbox_mAP: 0.0110  coco/bbox_mAP_50: 0.0240  coco/bbox_mAP_75: 0.0070  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0020  coco/bbox_mAP_l: 0.0160  data_time: 0.0212  time: 0.0789\n","08/07 14:53:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmdetection/work_dirs/rtmdet_tiny_1xb4-20e_raccoon/best_coco_bbox_mAP_epoch_1.pth is removed\n","08/07 14:53:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.0110 coco/bbox_mAP at 2 epoch is saved to best_coco_bbox_mAP_epoch_2.pth.\n","08/07 14:53:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 5/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:03:50  time: 0.3154  data_time: 0.0212  memory: 1422  loss: 2.4045  loss_cls: 1.6976  loss_bbox: 0.7069\n","08/07 14:53:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][10/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:03:58  time: 0.3554  data_time: 0.0220  memory: 1422  loss: 2.3665  loss_cls: 1.6692  loss_bbox: 0.6972\n","08/07 14:54:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][15/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:03:58  time: 0.3487  data_time: 0.0178  memory: 1422  loss: 2.3131  loss_cls: 1.6292  loss_bbox: 0.6840\n","08/07 14:54:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][20/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:04:00  time: 0.3583  data_time: 0.0189  memory: 1422  loss: 2.2719  loss_cls: 1.5980  loss_bbox: 0.6739\n","08/07 14:54:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][25/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:03:55  time: 0.3451  data_time: 0.0182  memory: 1422  loss: 2.2435  loss_cls: 1.5791  loss_bbox: 0.6645\n","08/07 14:54:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][30/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:03:50  time: 0.3158  data_time: 0.0175  memory: 1422  loss: 2.1625  loss_cls: 1.5155  loss_bbox: 0.6469\n","08/07 14:54:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][35/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:03:45  time: 0.3173  data_time: 0.0173  memory: 1422  loss: 2.0840  loss_cls: 1.4546  loss_bbox: 0.6293\n","08/07 14:54:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: rtmdet_tiny_1xb4-20e_raccoon_20230807_145300\n","08/07 14:54:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][40/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:03:39  time: 0.3133  data_time: 0.0171  memory: 1422  loss: 2.0145  loss_cls: 1.3977  loss_bbox: 0.6168\n","08/07 14:54:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][ 5/32]    eta: 0:00:04  time: 0.0891  data_time: 0.0263  memory: 325  \n","08/07 14:54:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][10/32]    eta: 0:00:02  time: 0.0871  data_time: 0.0255  memory: 325  \n","08/07 14:54:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][15/32]    eta: 0:00:01  time: 0.0854  data_time: 0.0258  memory: 325  \n","08/07 14:54:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][20/32]    eta: 0:00:01  time: 0.0723  data_time: 0.0157  memory: 325  \n","08/07 14:54:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][25/32]    eta: 0:00:00  time: 0.0724  data_time: 0.0162  memory: 325  \n","08/07 14:54:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][30/32]    eta: 0:00:00  time: 0.0720  data_time: 0.0163  memory: 325  \n","08/07 14:54:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n","Loading and preparing results...\n","DONE (t=0.37s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=1.58s).\n","Accumulating evaluation results...\n","DONE (t=0.21s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.353\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.751\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.278\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.212\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.367\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.394\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.528\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.607\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.477\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.618\n","08/07 14:54:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.353 0.751 0.278 -1.000 0.212 0.367\n","08/07 14:54:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][32/32]    coco/bbox_mAP: 0.3530  coco/bbox_mAP_50: 0.7510  coco/bbox_mAP_75: 0.2780  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.2120  coco/bbox_mAP_l: 0.3670  data_time: 0.0208  time: 0.0782\n","08/07 14:54:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmdetection/work_dirs/rtmdet_tiny_1xb4-20e_raccoon/best_coco_bbox_mAP_epoch_2.pth is removed\n","08/07 14:54:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.3530 coco/bbox_mAP at 3 epoch is saved to best_coco_bbox_mAP_epoch_3.pth.\n","08/07 14:54:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 5/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:03:43  time: 0.3449  data_time: 0.0282  memory: 1422  loss: 1.9508  loss_cls: 1.3433  loss_bbox: 0.6075\n","08/07 14:54:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][10/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:03:39  time: 0.3519  data_time: 0.0282  memory: 1422  loss: 1.8813  loss_cls: 1.2807  loss_bbox: 0.6006\n","08/07 14:54:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][15/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:03:34  time: 0.3228  data_time: 0.0184  memory: 1422  loss: 1.8277  loss_cls: 1.2313  loss_bbox: 0.5964\n","08/07 14:54:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][20/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:03:30  time: 0.2895  data_time: 0.0183  memory: 1422  loss: 1.7770  loss_cls: 1.1933  loss_bbox: 0.5837\n","08/07 14:54:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][25/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:03:26  time: 0.2725  data_time: 0.0178  memory: 1422  loss: 1.7384  loss_cls: 1.1613  loss_bbox: 0.5771\n","08/07 14:54:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][30/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:03:23  time: 0.2506  data_time: 0.0165  memory: 1422  loss: 1.6723  loss_cls: 1.1113  loss_bbox: 0.5610\n","08/07 14:54:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][35/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:03:19  time: 0.2469  data_time: 0.0168  memory: 1422  loss: 1.6034  loss_cls: 1.0519  loss_bbox: 0.5515\n","08/07 14:54:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: rtmdet_tiny_1xb4-20e_raccoon_20230807_145300\n","08/07 14:54:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][40/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:03:14  time: 0.2404  data_time: 0.0163  memory: 1422  loss: 1.5625  loss_cls: 1.0194  loss_bbox: 0.5432\n","08/07 14:54:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][ 5/32]    eta: 0:00:04  time: 0.0840  data_time: 0.0262  memory: 325  \n","08/07 14:54:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][10/32]    eta: 0:00:02  time: 0.0838  data_time: 0.0258  memory: 325  \n","08/07 14:54:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][15/32]    eta: 0:00:01  time: 0.0846  data_time: 0.0261  memory: 325  \n","08/07 14:54:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][20/32]    eta: 0:00:01  time: 0.0729  data_time: 0.0168  memory: 325  \n","08/07 14:54:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][25/32]    eta: 0:00:00  time: 0.0728  data_time: 0.0170  memory: 325  \n","08/07 14:54:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][30/32]    eta: 0:00:00  time: 0.0724  data_time: 0.0170  memory: 325  \n","08/07 14:54:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n","Loading and preparing results...\n","DONE (t=0.10s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=1.64s).\n","Accumulating evaluation results...\n","DONE (t=0.22s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.827\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.398\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.285\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.465\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.477\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.634\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.666\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.680\n","08/07 14:54:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.449 0.827 0.398 -1.000 0.285 0.465\n","08/07 14:54:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [4][32/32]    coco/bbox_mAP: 0.4490  coco/bbox_mAP_50: 0.8270  coco/bbox_mAP_75: 0.3980  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.2850  coco/bbox_mAP_l: 0.4650  data_time: 0.0218  time: 0.0786\n","08/07 14:54:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmdetection/work_dirs/rtmdet_tiny_1xb4-20e_raccoon/best_coco_bbox_mAP_epoch_3.pth is removed\n","08/07 14:54:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.4490 coco/bbox_mAP at 4 epoch is saved to best_coco_bbox_mAP_epoch_4.pth.\n","08/07 14:54:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 5/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:03:15  time: 0.2620  data_time: 0.0291  memory: 1422  loss: 1.5372  loss_cls: 0.9967  loss_bbox: 0.5405\n","08/07 14:54:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][10/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:03:12  time: 0.2625  data_time: 0.0291  memory: 1422  loss: 1.5270  loss_cls: 0.9926  loss_bbox: 0.5344\n","08/07 14:54:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][15/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:03:09  time: 0.2337  data_time: 0.0182  memory: 1422  loss: 1.4997  loss_cls: 0.9748  loss_bbox: 0.5249\n","08/07 14:54:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][20/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:03:06  time: 0.2314  data_time: 0.0184  memory: 1422  loss: 1.4773  loss_cls: 0.9616  loss_bbox: 0.5157\n","08/07 14:54:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][25/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:03:03  time: 0.2314  data_time: 0.0183  memory: 1422  loss: 1.4534  loss_cls: 0.9494  loss_bbox: 0.5040\n","08/07 14:54:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][30/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:03:00  time: 0.2313  data_time: 0.0177  memory: 1422  loss: 1.4454  loss_cls: 0.9405  loss_bbox: 0.5049\n","08/07 14:54:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][35/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:02:57  time: 0.2315  data_time: 0.0176  memory: 1422  loss: 1.4148  loss_cls: 0.9161  loss_bbox: 0.4987\n","08/07 14:54:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: rtmdet_tiny_1xb4-20e_raccoon_20230807_145300\n","08/07 14:54:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][40/40]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 0:02:54  time: 0.2249  data_time: 0.0174  memory: 1422  loss: 1.4010  loss_cls: 0.9014  loss_bbox: 0.4996\n","08/07 14:54:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 5 epochs\n","08/07 14:54:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][ 5/32]    eta: 0:00:05  time: 0.0884  data_time: 0.0273  memory: 325  \n","08/07 14:54:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][10/32]    eta: 0:00:03  time: 0.0913  data_time: 0.0272  memory: 325  \n","Traceback (most recent call last):\n","  File \"/content/mmdetection/tools/train.py\", line 133, in <module>\n","    main()\n","  File \"/content/mmdetection/tools/train.py\", line 129, in main\n","    runner.train()\n","  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/runner.py\", line 1745, in train\n","    model = self.train_loop.run()  # type: ignore\n","  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 102, in run\n","    self.runner.val_loop.run()\n","  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 363, in run\n","    self.run_iter(idx, data_batch)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 383, in run_iter\n","    outputs = self.runner.model.val_step(data_batch)\n","  File \"/usr/local/lib/python3.10/dist-packages/mmengine/model/base_model/base_model.py\", line 133, in val_step\n","    return self._run_forward(data, mode='predict')  # type: ignore\n","  File \"/usr/local/lib/python3.10/dist-packages/mmengine/model/base_model/base_model.py\", line 340, in _run_forward\n","    results = self(**data, mode=mode)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/mmdetection/mmdet/models/detectors/base.py\", line 94, in forward\n","    return self.predict(inputs, data_samples)\n","  File \"/content/mmdetection/mmdet/models/detectors/single_stage.py\", line 110, in predict\n","    results_list = self.bbox_head.predict(\n","  File \"/content/mmdetection/mmdet/models/dense_heads/base_dense_head.py\", line 197, in predict\n","    predictions = self.predict_by_feat(\n","  File \"/content/mmdetection/mmdet/models/dense_heads/base_dense_head.py\", line 279, in predict_by_feat\n","    results = self._predict_by_feat_single(\n","  File \"/content/mmdetection/mmdet/models/dense_heads/base_dense_head.py\", line 417, in _predict_by_feat_single\n","    return self._bbox_post_process(\n","  File \"/content/mmdetection/mmdet/models/dense_heads/base_dense_head.py\", line 479, in _bbox_post_process\n","    det_bboxes, keep_idxs = batched_nms(bboxes, results.scores,\n","  File \"/usr/local/lib/python3.10/dist-packages/mmcv/ops/nms.py\", line 296, in batched_nms\n","    nms_op = nms_cfg_.pop('type', 'nms')\n","  File \"/usr/local/lib/python3.10/dist-packages/mmengine/config/config.py\", line 170, in pop\n","    def pop(self, key, default=None):\n","KeyboardInterrupt\n","^C\n"]}],"source":["!python tools/train.py configs/rtmdet/rtmdet_tiny_1xb4-20e_raccoon.py"]},{"cell_type":"code","source":["#Check AP\n","!bash tools/dist_test.sh \\\n","    configs/rtmdet/rtmdet_tiny_1xb4-20e_raccoon.py \\\n","    /content/mmdetection/work_dirs/rtmdet_tiny_1xb4-20e_raccoon/best_coco_bbox_mAP_epoch_18.pth \\\n","    1 \\\n","    --out results.pkl \\\n","    --cfg-options test_evaluator.classwise=True"],"metadata":{"id":"TcmWYSEGsXDU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691420088554,"user_tz":-420,"elapsed":95,"user":{"displayName":"Ki·ªát Tr·∫ßn","userId":"13976749715371674650"}},"outputId":"4329441d-35a8-415d-fb15-893a1580f170"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/runpy.py\", line 187, in _run_module_as_main\n","    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n","  File \"/usr/lib/python3.10/runpy.py\", line 110, in _get_module_details\n","    __import__(pkg_name)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 228, in <module>\n","    _load_global_deps()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 168, in _load_global_deps\n","    ctypes.CDLL(lib_path, mode=ctypes.RTLD_GLOBAL)\n","  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n","    self._handle = _dlopen(self._name, mode)\n","KeyboardInterrupt\n","^C\n"]}]},{"cell_type":"markdown","metadata":{"id":"_vYQF5K2NqqI"},"source":["### Understand the log\n","From the log, we can have a basic understanding on the training process and know how well the detector is trained.\n","\n","First, since the dataset we are using is small, we loaded a pre-trained Faster R-CNN model and fine-tune it for detection.\n","The original Faster R-CNN is trained on COCO dataset that contains 80 classes but KITTI Tiny dataset only have 3 classes. Therefore, the last FC layers of the pre-trained Faster R-CNN for classification and regression have different weight shape and are not used.\n","\n","Second, after training, the detector is evaluated by the default VOC-style evaluation. The results show that the detector achieves 58.1 mAP on the val dataset, not bad!\n","\n","We can also check the tensorboard to see the curves."]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"_wpQGXu9aONh","outputId":"0baf32f4-4551-4247-b0c2-ece3c58e86b9","executionInfo":{"status":"error","timestamp":1691420092112,"user_tz":-420,"elapsed":3595,"user":{"displayName":"Ki·ªát Tr·∫ßn","userId":"13976749715371674650"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Launching TensorBoard..."]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-2d48d187ec36>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# see curves in tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tensorboard'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--logdir ./work_dirs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorboard/notebook.py\u001b[0m in \u001b[0;36m_start_magic\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_start_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;34m\"\"\"Implementation of the `%tensorboard` line magic.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorboard/notebook.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(args_string)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mparsed_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshlex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0mstart_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStartLaunched\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorboard/manager.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(arguments, timeout)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0mend_time_seconds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_time_seconds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mend_time_seconds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll_interval_seconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0msubprocess_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msubprocess_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# load tensorboard in colab\n","%load_ext tensorboard\n","\n","# see curves in tensorboard\n","%tensorboard --logdir ./work_dirs"]},{"cell_type":"markdown","metadata":{"id":"MfQ-yspZLuuI"},"source":["From the tensorboard, we can observe that changes of loss and learning rate. We can see the losses of each branch gradually decrease as the training goes by.\n","\n","## Test the Trained Detector\n","\n","After finetuning the detector, let's visualize the prediction results!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gOmfBennr5aw","executionInfo":{"status":"aborted","timestamp":1691420092116,"user_tz":-420,"elapsed":12,"user":{"displayName":"Ki·ªát Tr·∫ßn","userId":"13976749715371674650"}}},"outputs":[],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CHDYQSRNNDxt","executionInfo":{"status":"aborted","timestamp":1691420092117,"user_tz":-420,"elapsed":12,"user":{"displayName":"Ki·ªát Tr·∫ßn","userId":"13976749715371674650"}}},"outputs":[],"source":["from mmdet.apis import DetInferencer\n","import glob\n","\n","# Choose to use a config\n","config = 'configs/rtmdet/rtmdet_tiny_1xb4-20e_raccoon.py'\n","# Setup a checkpoint file to load\n","checkpoint = glob.glob('./work_dirs/rtmdet_tiny_1xb4-20e_raccoon/best_coco*.pth')[0]\n","\n","# Set the device to be used for evaluation\n","device = 'cuda:0'\n","\n","# Initialize the DetInferencer\n","inferencer = DetInferencer(config, checkpoint, device)\n","\n","# Use the detector to do inference\n","img = '/content/mmdetection/data/Racoon Images/images/raccoon-1.jpg'\n","result = inferencer(img, out_dir='./output')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zDzwbUsfN4lR","executionInfo":{"status":"aborted","timestamp":1691420092118,"user_tz":-420,"elapsed":12,"user":{"displayName":"Ki·ªát Tr·∫ßn","userId":"13976749715371674650"}}},"outputs":[],"source":["# Show the output image\n","from PIL import Image\n","Image.open('/content/mmdetection/output/vis/raccoon-1.jpg')"]},{"cell_type":"markdown","source":["###Valid Process"],"metadata":{"id":"jgXVYYFw69sb"}},{"cell_type":"code","source":["from mmdet.apis import DetInferencer\n","import os\n","import glob\n","\n","# Choose to use a config\n","config = 'configs/rtmdet/rtmdet_tiny_1xb4-20e_raccoon.py'\n","# Setup a checkpoint file to load\n","checkpoint = glob.glob('./work_dirs/rtmdet_tiny_1xb4-20e_raccoon/best_coco*.pth')[0]\n","\n","# Set the device to be used for evaluation\n","device = 'cuda:0'\n","\n","# Initialize the DetInferencer\n","inferencer = DetInferencer(config, checkpoint, device)\n","\n","# Use the detector to do inference\n","folder_path = \"/content/mmdetection/data/Racoon Images/images\"\n","image_files = glob.glob(os.path.join(folder_path, \"*.jpg\"))\n","for image_file in image_files:\n","  result = inferencer(image_file, out_dir='./output')"],"metadata":{"id":"F5XyEmN3-5re","executionInfo":{"status":"aborted","timestamp":1691420092119,"user_tz":-420,"elapsed":13,"user":{"displayName":"Ki·ªát Tr·∫ßn","userId":"13976749715371674650"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","\n","!zip -r output output"],"metadata":{"id":"PO4TVr7Y688Y","executionInfo":{"status":"aborted","timestamp":1691420092120,"user_tz":-420,"elapsed":14,"user":{"displayName":"Ki·ªát Tr·∫ßn","userId":"13976749715371674650"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["files.download('output.zip')"],"metadata":{"id":"wlWEDRk3_WGD","executionInfo":{"status":"aborted","timestamp":1691420092120,"user_tz":-420,"elapsed":14,"user":{"displayName":"Ki·ªát Tr·∫ßn","userId":"13976749715371674650"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F1L8o3rtc37M"},"source":["## What to Do Next?\n","\n","So far, we have learnt how to test and train a one-stage detector using MMDetection. To further explore MMDetection, you could do several other things as shown below:\n","\n","- Try YOLO series object detection using [MMYOLO](https://github.com/open-mmlab/mmyolo), also one of the OpenMMLab projects. In MMYOLO, not only can you try all the methods supported in MMDetection but also some YOLO series detectors.\n","- Try rotated object detection using [MMRotate](https://github.com/open-mmlab/mmrotate), also one of the OpenMMLab projects. In MMRotate, not only can you try all the methods supported in MMDetection but also some rotated object detectors.\n","- Try 3D object detection using [MMDetection3D](https://github.com/open-mmlab/mmdetection3d), also one of the OpenMMLab projects. In MMDetection3D, not only can you try all the methods supported in MMDetection but also some 3D object detectors.\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":0}